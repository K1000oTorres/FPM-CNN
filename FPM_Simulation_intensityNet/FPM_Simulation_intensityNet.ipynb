{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargue de las librerías\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import *\n",
    "from keras.layers import Input, Conv2D, concatenate, Add\n",
    "from keras.optimizers import *\n",
    "from math import pi as pi\n",
    "from scipy import signal\n",
    "from keras import backend as K\n",
    "from math import pi as pi\n",
    "import tensorflow as tf\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Función de activación cuadrática\n",
    "def activation_square(x):\n",
    "    return tf.square(x)\n",
    "\n",
    "# Carga un archivo y extrae dos columnas de datos numericos kx y ky que reoresentan coordenadas espaciales en una matriz LED\n",
    "# Convierte estos datos en un arreglo kxky y lo organiza como un arreglo transpuesto\n",
    "def spiral_kxky(filename, ledNum):\n",
    "    kxky = [[], []]\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            for j, value in enumerate(line.split(\",\")):\n",
    "                kxky[j].append(float(value))\n",
    "    kxky = np.asarray(kxky)\n",
    "    kxky = kxky.T\n",
    "    return kxky[:ledNum, :]\n",
    "\n",
    "# Recupera los pesos y los convierte en una representación de números complejos parte real e imaginaria\n",
    "# Calcula la magnitud y la fase de la imagen compleja y calcula el logaritmo de esta transformación\n",
    "# Muestra 6 gráficos: Magnitud y fase reconstruida,FFT, Magnitud y fase de la imagen de alta resolución orinal y FFT\n",
    "def show_result(model, show=0, noShow=10):\n",
    "    w_conv1 = model.get_layer('conv_O').get_weights()\n",
    "    w_conv1_array = np.asarray(w_conv1)\n",
    "    c_real = w_conv1_array[:, :, :, 0, :].reshape((imSize, imSize))\n",
    "    c_imag = w_conv1_array[:, :, :, 1, :].reshape((imSize, imSize))\n",
    "    \n",
    "    c_complex = c_real + 1j * c_imag  \n",
    "    c_abs = np.flip(np.flip(np.abs(c_complex), 0), 1)\n",
    "    c_phase = np.flip(np.flip(np.angle(c_complex), 0), 1)\n",
    "    c_complexFTLog = np.log(np.abs(np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(c_complex)))))\n",
    "    objFTLog = np.log(np.abs(np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(obj)))))\n",
    "    \n",
    "    if show:\n",
    "        plt.figure()\n",
    "        plt.subplot(231),plt.imshow(c_abs[noShow:imSize-noShow, noShow:imSize-noShow], cmap='gray'),plt.title('recover (abs)')\n",
    "        plt.subplot(232),plt.imshow(c_phase[noShow:imSize-noShow, noShow:imSize-noShow], cmap='gray'),plt.title('recover (phase)')\n",
    "        plt.subplot(233),plt.imshow(c_complexFTLog[noShow:imSize-noShow, noShow:imSize-noShow], cmap='gray'),plt.title('recover FT')\n",
    "        plt.subplot(234),plt.imshow(np.abs(obj[noShow:imSize-noShow, noShow:imSize-noShow]), cmap='gray'),plt.title('high res (abs)')\n",
    "        plt.subplot(235),plt.imshow(np.angle(obj[noShow:imSize-noShow, noShow:imSize-noShow]), cmap='gray'),plt.title('high res (phase)')\n",
    "        plt.subplot(236),plt.imshow(objFTLog[noShow:imSize-noShow, noShow:imSize-noShow], cmap='gray'),plt.title('high res FT')\n",
    "        plt.show()\n",
    "        \n",
    "    return c_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se configuran los parámetros\n",
    "\n",
    "wlength = 0.532*1e-6 # Longitud de onda de la luz verde visible\n",
    "NA = 0.1 # Apertura númerica del sitema óptico\n",
    "k0 = 2 * pi / wlength # Calcula el número de onda en el vacío\n",
    "spsize = (3.45*1e-6)/2 # Define el tamaño del pixel de la matriz de LEDs o el tamaño del pixel del sensor\n",
    "psize = spsize/4 # Establece el tamaño del pixel del sensor a una cuarta parte del tamaño del pixel de la matriz de LEDs\n",
    "imSize = 128 # tamaño de la imágen a reconstruir 128 x 128 pixeles\n",
    "imCenter = int(imSize / 2) # Calcula el centro de la imagen (64)\n",
    "arraysize = 15 # Define el tamaño del arreglo\n",
    "NAstep = 0.05 # Indica el incremento en la apertura númerica  que se utiliza para realizar calculos en diferentes ángulos o condiciones de enfoque\n",
    "index_downSample = 4 # downsample: index_downSample=4 # indice de submuestro util para reducir la carga computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue de las imagenes\n",
    "\n",
    "imgAmp = cv2.imread('cameraman.bmp', 0)+10 # Cargue de la imagen de amplitud en grises y se le suman 10 para evitar valores en 0\n",
    "imgAmp = cv2.resize(imgAmp, (imSize, imSize), interpolation=cv2.INTER_CUBIC).astype(float) # Redimensionamiento de la imagen de amplitud\n",
    "imgPhase = cv2.imread('westconcordorthophoto.bmp', 0) # Cargue de la imagen de la fase \n",
    "imgPhase = cv2.resize(imgPhase, (imSize, imSize), interpolation=cv2.INTER_CUBIC).astype(float) # Redimensionamiento de la imagen de fase\n",
    "imgPhase = cv2.normalize(imgPhase, None, -1, 1.0, cv2.NORM_MINMAX) # se normalizan los valores entre [-1,1]\n",
    "obj = imgAmp * np.exp(1j * 0.5 * pi * imgPhase) # Crea un objeto que combina la amplitud y fase en su forma compleja exponencial \n",
    "\n",
    "# Generación de la función de transferencia de corte\n",
    "\n",
    "dkxy = 2*pi/psize/(imSize-1) # Calcula el paso en el espacio de frecuencias y se usa para determinar las frecuencias que frecuencias del sistema óptico puede capturar\n",
    "cutoffFrequency = (NA * k0 / dkxy) # Calcula la frecuencia de corte\n",
    "center = [imCenter, imCenter] # Define el centro de la imagen en el espacio de frecuencias\n",
    "kYY, kXX = np.ogrid[:imSize, :imSize] # Crea 2 matrices de coordenadas para el espacio de frecuencias que contienen las posiciones de cada pixel en la imagen \n",
    "CTF = np.sqrt((kXX - center[0]) ** 2 + (kYY - center[1]) ** 2) <= cutoffFrequency # Calcula la función de transferencia de corte eb funcion de la distancia\n",
    "# desde el centro de la imagen y genera una matriz binaria (True o False) si se encuentra dentro del limite de corte\n",
    "CTF = CTF.astype(float) # Convierte a float \n",
    "\n",
    "# Se muestran las imagenes de Amplitud y Fase así como la funcion de transferencia de corte\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1),plt.imshow(imgAmp, cmap='gray'),plt.title('Amplitude')\n",
    "plt.subplot(1, 3, 2),plt.imshow(imgPhase, cmap='gray'),plt.title('Phase')\n",
    "plt.subplot(1, 3, 3),plt.imshow(CTF, cmap='gray'),plt.title('CTF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kxky shape: (225, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generación de imagenes de baja resolución \n",
    "\n",
    "imgs_train_input1 = np.ndarray((arraysize ** 2, imSize, imSize, 2)) # input real(PSF), -imag(PSF) Crea un arreglo vacio (225, 128, 128, 2)\n",
    "imgs_train_input2 = np.ndarray((arraysize ** 2, imSize, imSize, 2)) # input imag(PSF), real(PSF)  Crea un arreglo vacio (225, 128, 128, 2)\n",
    "kxky = spiral_kxky('spiral_kxky.txt', arraysize ** 2)   # Carga las coordenadas de frecuencia (kx,ky)\n",
    "print('kxky shape:',kxky.shape) # Imprime las dimensiones del arreglo\n",
    "for i in range(arraysize ** 2):\n",
    "    kx = kxky[i,0] * NAstep # Extrae la componente kx de la posicion i y la multiplica por NAstep\n",
    "    ky = kxky[i,1] * NAstep # Extrae la componente ky de la posicion i y la multiplica por NAstep\n",
    "    kxIllu = int(kx * k0 / dkxy) # Desplazamiento en el espacio de frecuencias, utilizando la longitud de onda y el paso en el espacio de frecuencias\n",
    "    kyIllu = int(ky * k0 / dkxy)\n",
    "    ctfIllu = np.roll(CTF, [kxIllu, kyIllu], axis=(0, 1)) # Desplaza la mattriz CTF en las direcciones kx y ky   \n",
    "    psfIllu = np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(ctfIllu))) # Realiza la IFFT 2D sobre el CTF desplazado y luego aplica un desplazamiento fftshift\n",
    "    psfIlluReal = np.real(psfIllu) # Extrae la parte real de la PSF iluminada\n",
    "    psfIlluImag = np.imag(psfIllu) # Extrae la parte imaginaria de la PSF iluminada\n",
    "    \n",
    "    imgs_train_input1[i, :, :, 0] = 1 * psfIlluReal\n",
    "    imgs_train_input1[i, :, :, 1] = -1 * psfIlluImag    \n",
    "    imgs_train_input2[i, :, :, 0] = 1 * psfIlluImag\n",
    "    imgs_train_input2[i, :, :, 1] = 1 * psfIlluReal\n",
    "\n",
    "# Enseña los resultados    \n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1),plt.imshow(imgs_train_input1[0, :, :, 0], cmap='gray'),plt.title('Input real(PSF)')\n",
    "plt.subplot(1, 2, 2),plt.imshow(imgs_train_input2[0, :, :, 0], cmap='gray'),plt.title('Input imag(PSF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_O (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │ input_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ input_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv_O[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], conv_O[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_1 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_2 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv_O (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m32,768\u001b[0m │ input_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ input_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ conv_O[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], conv_O[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> (128.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,768\u001b[0m (128.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> (128.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,768\u001b[0m (128.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Capas de entrada\n",
    "input_1 = Input((imSize, imSize, 2), name='input_1')  # channel 1: Pr, channel 2: -Pi\n",
    "input_2 = Input((imSize, imSize, 2), name='input_2')  # channel 1: Pi, channel 2: Pr\n",
    "\n",
    "# Definición de la capa Convolucional\n",
    "conv_O = Conv2D(1, imSize, activation=activation_square, padding='same', strides=index_downSample, \n",
    "                 kernel_initializer='one', bias_initializer='zero', use_bias=False, name='conv_O')\n",
    "# Generación de iamgenes de baja resolución\n",
    "conv1_1 = conv_O(input_1)\n",
    "conv1_2 = conv_O(input_2)\n",
    "addLayer = Add()([conv1_1, conv1_2]) # Una capa que combina las salidas de ambas convoluciones\n",
    "\n",
    "model = Model(inputs=[input_1, input_2], outputs=addLayer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 390ms/step\n"
     ]
    }
   ],
   "source": [
    "# Configuración de los pesos de la capa Conv2D\n",
    "\n",
    "weight_o = np.ndarray((1, imSize, imSize, 2, 1)) # 1 indica un solo filtro y 2 representa los canales real e imaginario\n",
    "weight_o[0, :, :, 0, 0] = np.flip(np.flip(np.real(obj), 1), 0) # Se establece el primer canal como la parte real del objeto\n",
    "weight_o[0, :, :, 1, 0] = np.flip(np.flip(np.imag(obj), 1), 0) # Se establece el segundo canal como la parte imaginaria del objeto\n",
    "model.get_layer('conv_O').set_weights(weight_o)\n",
    "\n",
    "# Se compila el modelo pero no se ajusta para su predicción debido a que el Lr= 0.0,por ende solo se obtienen las salidas sin actualizar los pesos\n",
    "model.compile(loss='mean_absolute_error', optimizer=Adam(learning_rate=0.0))\n",
    "imgs_test_predict = model.predict([imgs_train_input1, imgs_train_input2], batch_size=1, verbose=1)\n",
    "plt.figure() \n",
    "plt.imshow(imgs_test_predict[0, :, :, 0],cmap='gray'),plt.title('measurement')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 685ms/step - loss: 2882.9570\n",
      "Epoch 2/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 699ms/step - loss: 2160.4844\n",
      "Epoch 3/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 705ms/step - loss: 1035.9448\n",
      "Epoch 4/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 713ms/step - loss: 570.2302\n",
      "Epoch 5/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 699ms/step - loss: 368.0362\n",
      "Epoch 6/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 688ms/step - loss: 273.1741\n",
      "Epoch 7/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 717ms/step - loss: 218.0133\n",
      "Epoch 8/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 723ms/step - loss: 184.8916\n",
      "Epoch 9/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 739ms/step - loss: 162.4454\n",
      "Epoch 10/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 701ms/step - loss: 152.7919\n"
     ]
    }
   ],
   "source": [
    "# Configuración de los pesos iniciales\n",
    "weight_o[0, :, :, 0, 0] = np.flip(np.flip(np.sqrt(np.resize(imgs_test_predict[0, :, :, 0],(imSize,imSize))/(index_downSample**2)),1),0) # Redimensiona para asegurarse que tenga las dimensiones correctas\n",
    "weight_o[0, :, :, 1, 0] = np.flip(np.flip(np.sqrt(np.resize(imgs_test_predict[0, :, :, 0],(imSize,imSize))/(index_downSample**2)),1),0) # Se calcula la raiz cuadrada de la imagen redimensionada, normalizando por el factor de downsampling\n",
    "model.get_layer('conv_O').set_weights(weight_o)\n",
    "\n",
    "# Se entrena el modelo\n",
    "adam = Adam(learning_rate=1.0)\n",
    "model.compile(loss='mean_absolute_error', optimizer=adam)\n",
    "history = model.fit([imgs_train_input1, imgs_train_input2], imgs_test_predict, batch_size=1, epochs=10, verbose=1, shuffle=False)\n",
    "imRecover = show_result(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
