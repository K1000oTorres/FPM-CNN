{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, concatenate, Add\n",
    "from keras.optimizers import *\n",
    "from math import pi as pi\n",
    "from scipy import signal\n",
    "from keras import backend as K\n",
    "from math import pi as pi\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def activation_square(x):\n",
    "    return np.square(x)\n",
    "\n",
    "\n",
    "def spiral_kxky(filename, ledNum):\n",
    "    kxky = [[], []]\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            for j, value in enumerate(line.split(\",\")):\n",
    "                kxky[j].append(np.float(value))\n",
    "    kxky = np.asarray(kxky)\n",
    "    kxky = kxky.T\n",
    "    return kxky[:ledNum, :]\n",
    "\n",
    "\n",
    "def show_result(model, show=0, noShow=10):\n",
    "    w_conv1 = model.get_layer('conv_O').get_weights()\n",
    "    w_conv1_array = np.asarray(w_conv1)\n",
    "    c_real = w_conv1_array[:, :, :, 0, :].reshape((imSize, imSize))\n",
    "    c_imag = w_conv1_array[:, :, :, 1, :].reshape((imSize, imSize))\n",
    "    \n",
    "    c_complex = c_real + 1j * c_imag  \n",
    "    c_abs = np.flip(np.flip(np.abs(c_complex), 0), 1)\n",
    "    c_phase = np.flip(np.flip(np.angle(c_complex), 0), 1)\n",
    "    c_complexFTLog = np.log(np.abs(np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(c_complex)))))\n",
    "    objFTLog = np.log(np.abs(np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(obj)))))\n",
    "    \n",
    "    if show:\n",
    "        plt.figure()\n",
    "        plt.subplot(231),plt.imshow(c_abs[noShow:imSize-noShow, noShow:imSize-noShow], cmap='gray'),plt.title('recover (abs)')\n",
    "        plt.subplot(232),plt.imshow(c_phase[noShow:imSize-noShow, noShow:imSize-noShow], cmap='gray'),plt.title('recover (phase)')\n",
    "        plt.subplot(233),plt.imshow(c_complexFTLog[noShow:imSize-noShow, noShow:imSize-noShow], cmap='gray'),plt.title('recover FT')\n",
    "        plt.subplot(234),plt.imshow(np.abs(obj[noShow:imSize-noShow, noShow:imSize-noShow]), cmap='gray'),plt.title('high res (abs)')\n",
    "        plt.subplot(235),plt.imshow(np.angle(obj[noShow:imSize-noShow, noShow:imSize-noShow]), cmap='gray'),plt.title('high res (phase)')\n",
    "        plt.subplot(236),plt.imshow(objFTLog[noShow:imSize-noShow, noShow:imSize-noShow], cmap='gray'),plt.title('high res FT')\n",
    "        plt.show()\n",
    "        \n",
    "    return c_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "wlength = 0.532*1e-6\n",
    "NA = 0.1\n",
    "k0 = 2 * pi / wlength\n",
    "spsize = (3.45*1e-6)/2\n",
    "psize = spsize/4\n",
    "imSize = 128\n",
    "imCenter = int(imSize / 2)\n",
    "arraysize = 15\n",
    "NAstep = 0.05\n",
    "index_downSample = 1 # downsample: index_downSample=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "imgAmp = cv2.imread('cameraman.bmp', 0)+10\n",
    "imgAmp = cv2.resize(imgAmp, (imSize, imSize), interpolation=cv2.INTER_CUBIC).astype(float) # input amplitude\n",
    "imgPhase = cv2.imread('westconcordorthophoto.bmp', 0)\n",
    "imgPhase = cv2.resize(imgPhase, (imSize, imSize), interpolation=cv2.INTER_CUBIC).astype(float) # input phase\n",
    "imgPhase = cv2.normalize(imgPhase, None, -1, 1.0, cv2.NORM_MINMAX)\n",
    "obj = imgAmp * np.exp(1j * 0.5 * pi * imgPhase)\n",
    "\n",
    "# Generate CTF\n",
    "dkxy = 2*pi/psize/(imSize-1)\n",
    "cutoffFrequency = (NA * k0 / dkxy)\n",
    "center = [imCenter, imCenter]\n",
    "kYY, kXX = np.ogrid[:imSize, :imSize]\n",
    "CTF = np.sqrt((kXX - center[0]) ** 2 + (kYY - center[1]) ** 2) <= cutoffFrequency\n",
    "CTF = CTF.astype(float)\n",
    "\n",
    "# Show input image and CTF\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1),plt.imshow(imgAmp, cmap='gray'),plt.title('Amplitude')\n",
    "plt.subplot(1, 3, 2),plt.imshow(imgPhase, cmap='gray'),plt.title('Phase')\n",
    "plt.subplot(1, 3, 3),plt.imshow(CTF, cmap='gray'),plt.title('CTF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kxky shape: (225, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generate low res images\n",
    "imgs_train_input1 = np.ndarray((arraysize ** 2, imSize, imSize, 2)) # input real(PSF), -imag(PSF)\n",
    "imgs_train_input2 = np.ndarray((arraysize ** 2, imSize, imSize, 2)) # input imag(PSF), real(PSF)\n",
    "kxky = spiral_kxky('spiral_kxky.txt', arraysize ** 2)   # load kx, ky here\n",
    "print('kxky shape:',kxky.shape)\n",
    "for i in range(arraysize ** 2):\n",
    "    kx = kxky[i,0] * NAstep\n",
    "    ky = kxky[i,1] * NAstep\n",
    "    kxIllu = int(kx * k0 / dkxy)\n",
    "    kyIllu = int(ky * k0 / dkxy)\n",
    "    ctfIllu = np.roll(CTF, [kxIllu, kyIllu], axis=(0, 1))    \n",
    "    psfIllu = np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(ctfIllu)))\n",
    "    psfIlluReal = np.real(psfIllu)\n",
    "    psfIlluImag = np.imag(psfIllu)\n",
    "    \n",
    "    imgs_train_input1[i, :, :, 0] = 1 * psfIlluReal\n",
    "    imgs_train_input1[i, :, :, 1] = -1 * psfIlluImag    \n",
    "    imgs_train_input2[i, :, :, 0] = 1 * psfIlluImag\n",
    "    imgs_train_input2[i, :, :, 1] = 1 * psfIlluReal\n",
    "\n",
    "# show result    \n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1),plt.imshow(imgs_train_input1[0, :, :, 0], cmap='gray'),plt.title('Input real(PSF)')\n",
    "plt.subplot(1, 2, 2),plt.imshow(imgs_train_input2[0, :, :, 0], cmap='gray'),plt.title('Input imag(PSF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 128, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_O (Conv2D)                 (None, 128, 128, 1)  32768       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 1)  0           conv_O[0][0]                     \n",
      "                                                                 conv_O[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 32,768\n",
      "Trainable params: 32,768\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layer\n",
    "input_1 = Input((imSize, imSize, 2), name='input_1')  # channel 1: Pr, channel 2: -Pi\n",
    "input_2 = Input((imSize, imSize, 2), name='input_2')  # channel 1: Pi, channel 2: Pr\n",
    "# define O\n",
    "conv_O = Conv2D(1, imSize, activation=activation_square, padding='same', strides=index_downSample, \n",
    "                 kernel_initializer='one', bias_initializer='zero', use_bias=False, name='conv_O')\n",
    "# generate low res images\n",
    "conv1_1 = conv_O(input_1)\n",
    "conv1_2 = conv_O(input_2)\n",
    "addLayer = Add()([conv1_1, conv1_2])\n",
    "\n",
    "model = Model(inputs=[input_1, input_2], outputs=addLayer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 2s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# set high resolution image as the conv2D layer's weight\n",
    "weight_o = np.ndarray((1, imSize, imSize, 2, 1))\n",
    "weight_o[0, :, :, 0, 0] = np.flip(np.flip(np.real(obj), 1), 0)\n",
    "weight_o[0, :, :, 1, 0] = np.flip(np.flip(np.imag(obj), 1), 0)\n",
    "model.get_layer('conv_O').set_weights(weight_o)\n",
    "\n",
    "# predict to get low resolution image sequences\n",
    "model.compile(loss='mean_absolute_error', optimizer=Adam(lr = 0.0, decay = 0.0))\n",
    "imgs_test_predict = model.predict([imgs_train_input1, imgs_train_input2], batch_size=1, verbose=1)\n",
    "plt.figure() \n",
    "plt.imshow(imgs_test_predict[0, :, :, 0],cmap='gray'),plt.title('measurement')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 888.7354\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 551.9356\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 380.4316\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 283.8251\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 198.9694\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 140.9675\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 108.2109\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 87.8272\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 75.1848\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 3s 12ms/step - loss: 66.0594\n"
     ]
    }
   ],
   "source": [
    "# set low res image as the initial weight\n",
    "weight_o[0, :, :, 0, 0] = np.flip(np.flip(np.sqrt(np.resize(imgs_test_predict[0, :, :, 0],(imSize,imSize))/(index_downSample**2)),1),0) \n",
    "weight_o[0, :, :, 1, 0] = np.flip(np.flip(np.sqrt(np.resize(imgs_test_predict[0, :, :, 0],(imSize,imSize))/(index_downSample**2)),1),0)\n",
    "model.get_layer('conv_O').set_weights(weight_o)\n",
    "\n",
    "# train net\n",
    "adam = Adam(lr = 1, amsgrad=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=adam)\n",
    "history = model.fit([imgs_train_input1, imgs_train_input2], imgs_test_predict, batch_size=1, epochs=10, verbose=1, shuffle=False)\n",
    "imRecover = show_result(model, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
